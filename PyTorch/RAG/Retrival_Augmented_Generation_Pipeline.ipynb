{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run a local RAG pipeline from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is RAG?\n",
    "\n",
    "- Retrieval - Find relevant info given a query\n",
    "- Augmented - Take relevant info and augment our input (prompt) to an LLM with that relevant info\n",
    "- Generation - Take the first two steps and pass them to an LLM for generative outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why RAG?\n",
    "\n",
    "Improve generation outputs of LLMS\n",
    "\n",
    "1. Prevents hallucinations - good looking text that is not necessarily factual\n",
    "2. Work with custom data not internet-scale data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can RAG be used for?\n",
    "\n",
    "1. Customer support Q&A chat\n",
    "2. Email chain analysis\n",
    "3. Company internal documentation chat\n",
    "4. Textbook Q&A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why local?\n",
    "\n",
    "1. Privacy - private documentation that you don't want to send to an API\n",
    "2. Speed - no need to send data across the internet\n",
    "3. Cost - No cost if using own hardware\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we're going to build\n",
    "\n",
    "- We're going to build RAG pipeline which enables us to chat with a PDF document, specifically an open-source nutrition textbook, ~1200 pages long.\n",
    "\n",
    "- We'll write the code to:\n",
    "\n",
    "1. Open a PDF document (you could use almost any PDF here).\n",
    "2. Format the text of the PDF textbook ready for an embedding model (this process is known as text splitting/chunking).\n",
    "3. Embed all of the chunks of text in the textbook and turn them into numerical representation which we can store for later.\n",
    "4. Build a retrieval system that uses vector search to find relevant chunks of text based on a query.\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "   Generate an answer to a query based on passages from the textbook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document/text processing and embedding creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and open PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File human-nutrition-text.pdf exists\n"
     ]
    }
   ],
   "source": [
    "# Import PDF\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Get pdf document path\n",
    "pdf_path = \"human-nutrition-text.pdf\"\n",
    "\n",
    "# Download PDF\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"[INFO] file doesn't exist, downloading...\")\n",
    "\n",
    "    # Enter the URL of the pdf\n",
    "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition/open/download?type=pdf\"\n",
    "\n",
    "    # The local file name to save downloaded file\n",
    "    filename = pdf_path\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the file and save it\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"[INFO] The file has been downloaded and saved as{filename}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Failed to download the file. Status code : {response.status_code}\")\n",
    "\n",
    "else:\n",
    "    print(f\"[INFO] File {pdf_path} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 500.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "667it [00:01, 585.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -17,\n",
       "  'page_char_count': 15,\n",
       "  'page_word_count': 2,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 3.75,\n",
       "  'text': 'Human Nutrition'},\n",
       " {'page_number': -16,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open PDF\n",
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # More text formatting functions can go in here\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):\n",
    "        text= page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        pages_and_texts.append({\"page_number\": page_number - 17,\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 396,\n",
       "  'page_char_count': 1768,\n",
       "  'page_word_count': 293,\n",
       "  'page_sentence_count_raw': 17,\n",
       "  'page_token_count': 442.0,\n",
       "  'text': 'Iron Red blood cells contain the oxygen-carrier protein hemoglobin. It is composed of four globular peptides, each containing a heme complex. In the center of each heme, lies iron (Figure 11.2). Iron is needed for the production of other iron- containing proteins such as myoglobin. Myoglobin is a protein found in the muscle tissues that enhances the amount of available oxygen for muscle contraction. Iron is also a key component of hundreds of metabolic enzymes. Many of the proteins of the electron-transport chain contain iron–sulfur clusters involved in the transfer of high-energy electrons and ultimately ATP synthesis. Iron is also involved in numerous metabolic reactions that take place mainly in the liver and detoxify harmful substances. Moreover, iron is required for DNA synthesis. The great majority of iron used in the body is that recycled from the continuous breakdown of red blood cells. Figure 11.2 The Structure of Hemoglobin Hemoglobin is composed of four peptides. Each contains a heme group with iron in the center. The iron in hemoglobin binds to oxygen in the capillaries of the lungs and transports it to cells where the oxygen is released. If iron level is low hemoglobin is not synthesized in sufficient amounts and the oxygen-carrying capacity of red blood cells is reduced, resulting in anemia. When iron levels are low in the diet the small intestine more efficiently absorbs iron in an attempt to compensate for the low dietary intake, but this process cannot make up for the excessive loss of iron that occurs with chronic blood loss or low intake. When blood cells are decommissioned for use, the body recycles the iron back to the bone marrow where red blood cells are made. The body stores some iron in the bone marrow, liver, 396'},\n",
       " {'page_number': 338,\n",
       "  'page_char_count': 666,\n",
       "  'page_word_count': 99,\n",
       "  'page_sentence_count_raw': 3,\n",
       "  'page_token_count': 166.5,\n",
       "  'text': 'Another common thiamin deficiency known as Wernicke- Korsakoff syndrome can cause similar symptoms as beriberi such as confusion, loss of coordination, vision changes, hallucinations, and may progress to coma and death. This condition is specific to alcoholics as diets high in alcohol can cause thiamin deficiency. Other individuals at risk include individuals who also consume diets typically low in micronutrients such as those with eating disorders, elderly, and individuals who have gone through gastric bypass surgery.5 Figure 9.10 The Role of Thiamin Image by Allison Calabrese / CC BY 4.0 Figure 9.11 Beriberi, Thiamin Deficiency Water-Soluble Vitamins | 338'},\n",
       " {'page_number': 156,\n",
       "  'page_char_count': 688,\n",
       "  'page_word_count': 126,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 172.0,\n",
       "  'text': 'Foods GI Value Low GI Foods (< 55) Apple, raw 36 Orange, raw 43 Banana, raw 51 Mango, raw 51 Carrots, boiled 39 Taro, boiled 53 Corn tortilla 46 Spaghetti (whole wheat) 37 Baked beans 48 Soy milk 34 Skim milk 37 Whole milk 39 Yogurt, fruit 41 Yogurt, plain 14 Icecream 51 Medium GI Foods (56–69) Pineapple, raw 59 Cantaloupe 65 Mashed potatoes 70 Whole-wheat bread 69 Brown rice 55 Cheese pizza 60 Sweet potato, boiled 63 Macaroni and cheese 64 Popcorn 65 High GI Foods (70 and higher) Banana (over-ripe) 82 Corn chips 72 Pretzels 83 White bread 70 White rice 72 Bagel 72 Rice milk 86 Cheerios 74 Raisin Bran 73 Fruit roll-up 99 Gatorade 78 Digestion and Absorption of Carbohydrates | 156'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Human Nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15</td>\n",
       "      <td>188</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>47.00</td>\n",
       "      <td>Human Nutrition UNIVERSITY OF HAWAI‘I AT MĀNOA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-14</td>\n",
       "      <td>607</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>151.75</td>\n",
       "      <td>Human Nutrition by University of Hawai‘i at Mā...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13</td>\n",
       "      <td>827</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>206.75</td>\n",
       "      <td>Contents Preface xi About the Contributors xii...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0          -17               15                2                        1   \n",
       "1          -16                0                1                        1   \n",
       "2          -15              188               26                        1   \n",
       "3          -14              607              100                        5   \n",
       "4          -13              827              130                        4   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              3.75                                    Human Nutrition  \n",
       "1              0.00                                                     \n",
       "2             47.00  Human Nutrition UNIVERSITY OF HAWAI‘I AT MĀNOA...  \n",
       "3            151.75  Human Nutrition by University of Hawai‘i at Mā...  \n",
       "4            206.75  Contents Preface xi About the Contributors xii...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects",
   "language": "python",
   "name": "ml_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
